{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-wfp-02-02-02 - Snow Cover Climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snow Cover Climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Snow Cover Climatology'),\n",
    "                ('abstract', 'Snow Cover Climatology'),\n",
    "                ('id', 'ewf-wfp-02-02-02')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "#                     ('value', 'CentralAsia'),\n",
    "#                     ('title', 'Name of Region'),\n",
    "#                     ('abstract', 'Name of the region of interest'),\n",
    "#                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAggCat = dict([('id', 'indexAggCat'),\n",
    "                    ('value', 'better-wfp-02-02-01'),\n",
    "                    ('title', 'indexAggCat'),\n",
    "                    ('abstract', 'index to access catalog of aggregated land surface temperature time series'),\n",
    "                    ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikeyAggCat = dict([('id', 'apikeyAggCat'),\n",
    "                     ('value', ''),\n",
    "                     ('title', 'apikeyAggCat'),\n",
    "                     ('abstract', 'apikey to access indexAggCat catalog'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n sdays\n",
    "input_identifiers = ('26DDF6E2F0A9653EE4878D934A9EF222EA7EB245', '2EC65A47B59254A6E92D996DA4FEFE061896144D')\n",
    "#input_identifiers = ('2EBB24856B5DBB3F4121FEEA23A6AA9B8782E3BA', 'DB57830AB8372416127C6AD483C5C4334568FB45')\n",
    "\n",
    "#2EBB24856B5DBB3F4121FEEA23A6AA9B8782E3BA\thttps://catalog.terradue.com/better-wfp-02-02-01/search?format=atom&uid=2EBB24856B5DBB3F4121FEEA23A6AA9B8782E3BA\thttps://store.terradue.com/better-wfp-02-02-01/_results/workflows/ec_better_ewf_wfp_02_02_01_ewf_wfp_02_02_01_1_10/run/44b5108a-ea95-11e9-8601-0242ac110026/0138766-181221095105003-oozie-oozi-W/6063aa7b-07c7-4658-8ffc-263ceb55de9c/SCStartSeasonDate_MTerra_h23v05_2015_2016.tif\t2015-08-05T00:00:00.0000000Z\t2016-07-27T00:00:00.0000000Z\t2019-10-09T13:31:44.0879880+00:00\tOutput SCStartSeasonDate_MTerra_h23v05_2015_2016.tif\n",
    "\n",
    "#DB57830AB8372416127C6AD483C5C4334568FB45\thttps://catalog.terradue.com/better-wfp-02-02-01/search?format=atom&uid=DB57830AB8372416127C6AD483C5C4334568FB45\thttps://store.terradue.com/better-wfp-02-02-01/_results/workflows/ec_better_ewf_wfp_02_02_01_ewf_wfp_02_02_01_1_10/run/f0ae1d30-ee93-11e9-ae3d-0242ac110003/0147245-181221095105003-oozie-oozi-W/1b4cb7b7-0986-4393-882d-fc34d9d11afb/SCStartSeasonDate_MTerra_h23v05_2016_2017.tif\t2016-08-04T00:00:00.0000000Z\t2017-07-28T00:00:00.0000000Z\t2019-10-14T15:50:59.6852860+00:00\tOutput SCStartSeasonDate_MTerra_h23v05_2016_2017.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ['https://catalog.terradue.com/better-wfp-02-02-01/search?format=atom&uid={0}'.format(pid) for pid in input_identifiers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/dev/ewf-wfp-02-02-02/src/main/app-resources/notebook/libexec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import cioppy\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import copy\n",
    "\n",
    "import pdb\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,title,startdate,enddate,wkt',creds='{}:{}'.format(indexAggCat['value'],apikeyAggCat['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    \n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, output_projection=None, output_geotransform=None, mask=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "        \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "    output.FlushCache()\n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "def matrix_sum(mat1, mat2, no_data_value=None):\n",
    "    if no_data_value is not None:\n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = 0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = 0\n",
    "            \n",
    "            \n",
    "    msum = mat1 + mat2\n",
    "        \n",
    "    msum[(mat1 == 0)] = 0\n",
    "    msum[(mat2 == 0)] = 0\n",
    "        \n",
    "    return msum\n",
    "    \n",
    "    \n",
    "def calc_average(matrix_list, n_years):\n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    result = matrix_list[0]\n",
    "    for i in range(1, n_years):\n",
    "        result = matrix_sum(result, matrix_list[i])\n",
    "    \n",
    "    return np.divide(result, (n_years*1.00))\n",
    "'''\n",
    "\n",
    "\n",
    "#\n",
    "# sums mat1 to mat2\n",
    "# adds 1 to mat_n_vals where != no_data_value \n",
    "#\n",
    "\n",
    "def matrix_sum(mat1, mat2, mat_n_vals, no_data_value):\n",
    "\n",
    "    mat2_0and1s = np.zeros(mat2.shape)\n",
    "    \n",
    "    mat2_0and1s[mat2 != no_data_value] = 1\n",
    "    \n",
    "    \n",
    "    mat_n_vals = mat2_0and1s;\n",
    "    \n",
    "    \n",
    "    #msum = mat1\n",
    "    \n",
    "    msum = copy.deepcopy(mat1)\n",
    "    \n",
    "    msum[mat2 != no_data_value] = mat1[mat2 != no_data_value] + mat2[mat2 != no_data_value]\n",
    "    \n",
    "    msum[np.logical_and(mat1 == no_data_value, mat2 != no_data_value) ] = mat2[np.logical_and(mat1 == no_data_value, mat2 != no_data_value) ]\n",
    "    \n",
    "    msum[np.logical_and(mat1 == no_data_value, mat2 == no_data_value) ] = -9999\n",
    "\n",
    "    return msum, mat_n_vals\n",
    "\n",
    "\n",
    "#\n",
    "# calcs avg of matrix_list\n",
    "# it takes into account pixels with no_data_values in the time series \n",
    "# faster than calc_average_circular_mean\n",
    "#\n",
    "def calc_average_faster(matrix_list, no_data_value):\n",
    "    \n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    result = matrix_list[0]\n",
    "    \n",
    "  \n",
    "    mat_n_vals = np.zeros(result.shape)\n",
    "    mat_n_vals[result != no_data_value] = 1\n",
    "    \n",
    "    for i in range(1, len(matrix_list)):\n",
    "     \n",
    "        result, mat_n_vals_of_sum = matrix_sum(result, matrix_list[i], mat_n_vals, no_data_value)\n",
    "        \n",
    "        mat_n_vals = mat_n_vals + mat_n_vals_of_sum\n",
    "    \n",
    "\n",
    "    # to avoid division by 0!!\n",
    "    mat_n_vals[mat_n_vals == 0] = no_data_value\n",
    "\n",
    "    result = np.divide(result, mat_n_vals)\n",
    "    \n",
    "    # set as no data value pixels that are no data values in all time series\n",
    "    result[mat_n_vals == no_data_value] = no_data_value\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "#\n",
    "# calcs avg of matrix_list\n",
    "# it takes into account pixels with no_data_values in the time series \n",
    "# it has option for circular mean\n",
    "#\n",
    "def calc_average_circular_mean (snow_matrix_list, no_data_value, apply_circular_mean = False):\n",
    "\n",
    "    mean_mat = np.ones(snow_matrix_list[0].shape) * no_data_value\n",
    "\n",
    "    for i in range(snow_matrix_list[0].shape[0]):\n",
    "        for j in range(snow_matrix_list[0].shape[1]):       \n",
    "            vals = []\n",
    "            for k in range(len(snow_matrix_list)):\n",
    "                v = snow_matrix_list[k][i,j]\n",
    "                if (v != no_data_value):\n",
    "                    vals.append(v)\n",
    "        \n",
    "            if len(vals) > 0:\n",
    "                #print(np.mean(vals))\n",
    "            \n",
    "                if (apply_circular_mean):\n",
    "                    mean_mat[i,j] = stats.circmean(vals, high=365, low=1)\n",
    "                else:\n",
    "                    mean_mat[i,j] = np.mean(vals)\n",
    "                    \n",
    "    return mean_mat\n",
    "\n",
    "\n",
    "def calc_lta(file_list, apply_circular_mean):\n",
    "    \n",
    "    \n",
    "    if file_list:\n",
    "        \n",
    "        n_years = len(file_list)\n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        print('Aggregations converted to matrices')\n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        \n",
    "        #print('no data value' + str(no_data_value))\n",
    "        \n",
    "        # change no data value to -9999\n",
    "        new_no_data_value = -9999\n",
    "        for i in range(len(agr_period_matrix)):\n",
    "            agr_period_matrix[i] = agr_period_matrix[i].astype(int)\n",
    "            agr_period_matrix[i][agr_period_matrix[i] == no_data_value] = new_no_data_value\n",
    "        no_data_value = new_no_data_value\n",
    "        \n",
    "        #print(agr_period_matrix[0])\n",
    "        \n",
    "        #print('no data value' + str(no_data_value))\n",
    "        \n",
    "        if apply_circular_mean:\n",
    "            lta = calc_average_circular_mean (agr_period_matrix, no_data_value, apply_circular_mean)\n",
    "        else:\n",
    "            lta = calc_average_faster(agr_period_matrix, no_data_value)\n",
    "        \n",
    "     \n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def write_output(temp_folder, lta, period_start_date, period_end_date, product_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    \n",
    " \n",
    "    output_name = os.path.join(temp_folder, '_'.join(['LTA', product_type, region, str(period_start_date.year), str(period_end_date.year)]) + '.tif' )\n",
    "    \n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    return output_name\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return dat\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    #first_date = get_formatted_date(first_date)\n",
    "    #last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metadata = get_input_metadata(input_references)\n",
    "#print(input_metadata)\n",
    "#file_list = [os.path.join(data_path, in_id.split('/')[-1]) for in_id in input_identifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_circular_mean = False\n",
    "\n",
    "if 'SeasonDate' in input_metadata['title'].iloc[0]:  \n",
    "    apply_circular_mean = True\n",
    "\n",
    "print('Apply circular mean: ' + str(apply_circular_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metadata['enclosure']]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_metadata = get_input_metadata(input_references)\n",
    "#N = nv\n",
    "\n",
    "#file_list = [os.path.join(data_path, in_id.split('/')[-1]) for in_id in input_identifiers]\n",
    "#file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metadata['enclosure']]\n",
    "\n",
    "#file_list\n",
    "\n",
    "lta, projection, geotransform, no_data_value, data_type = calc_lta(file_list, apply_circular_mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(lta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "filename = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')\n",
    "\n",
    "#startdate = '2015-01-05\n",
    "#enddate = '2017-01-25'\n",
    "\n",
    "#startdate = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')[-2]\n",
    "#enddate = os.path.splitext(os.path.basename(file_list[-1]))[0].split('_')[-1]\n",
    "\n",
    "#startdate = dt.datetime.strptime(startdate, '%Y')\n",
    "#enddate = dt.datetime.strptime(enddate, '%Y')\n",
    "\n",
    "startdate = input_metadata.sort_values('startdate')['startdate'].iloc[0]\n",
    "enddate = input_metadata.sort_values('enddate')['enddate'].iloc[-1]\n",
    "region = filename[-3]\n",
    "prod_type = filename[0] + '_' + filename[-4]\n",
    "print(filename)\n",
    "print(region)\n",
    "print(prod_type)\n",
    "\n",
    "\n",
    "if lta is not None:\n",
    "    #pdb.set_trace()\n",
    "    filename = write_output(output_folder, lta, startdate, enddate, prod_type, region, projection, geotransform, 'GTiff', no_data_value, gdal.GDT_Int32)\n",
    "    print(filename)\n",
    "    startdate = input_metadata[input_metadata['startdate'] == min(input_metadata['startdate'])]['startdate'].iloc[0].strftime('%Y-%m-%dT00:00:00Z')\n",
    "    enddate = input_metadata[input_metadata['enddate'] == max(input_metadata['enddate'])]['enddate'].iloc[0].strftime('%Y-%m-%dT00:00:00Z')\n",
    "    wkt = input_metadata['wkt'].iloc[0]\n",
    "    write_properties_file(filename, startdate, enddate, wkt)\n",
    "    \n",
    "#lta[310,210]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region\n",
    "\n",
    "prod_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
